{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d0b872",
   "metadata": {},
   "source": [
    "# Redes neuronales para clasificación de imágenes\n",
    "Considere el conjunto de imágenes de Emojis, las cuales son trazos de emojis de 5 tipos. Para estas imágenes, realice lo siguiente:\n",
    "\n",
    "-Procesa cada una de las imágenes de tal manera que para cada imagen de color, se obtenga una imagen binaria de 32 x 32 donde el trazo principal del emoji esté centrado y ocupando el mayor espacio posible de la imagen. \n",
    "\n",
    "-Con las imágenes binarias, ajusta un modelo MLP y evalúa su rendimiento.\n",
    "\n",
    "-Ajusta y evalúa una CNN para las imágenes binarias (25 puntos extras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a68286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Emojis'\n",
    "\n",
    "emojis = []\n",
    "labels = ['Angry', 'Happy', 'Poo', 'Sad', 'Surprised']\n",
    "for label in labels:\n",
    "    folder = os.path.join(path, label)\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                emojis.append((img, label))\n",
    "\n",
    "print(\"Número total de imágenes cargadas:\", len(emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra una imagen de cada categoría\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    for img, img_label in emojis:\n",
    "        if img_label == label:\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de las imágenes. \n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Imagen binaria (fondo blanco, trazos negros)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        min_area = 30\n",
    "        all_points = np.vstack([cnt for cnt in contours if cv2.contourArea(cnt) > min_area])\n",
    "        x, y, w, h = cv2.boundingRect(all_points)\n",
    "        roi = binary[y:y+h, x:x+w]  # Usar la imagen binaria\n",
    "        roi_resized = cv2.resize(roi, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "        padded = np.pad(roi_resized, ((2, 2), (2, 2)), mode='constant', constant_values=0)\n",
    "        return padded\n",
    "    else:\n",
    "        return cv2.resize(binary, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "preprocessed_emojis = [(preprocess_image(img), label) for img, label in emojis]\n",
    "print(\"Número total de imágenes preprocesadas:\", len(preprocessed_emojis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217b6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra una imagen de cada categoria preprocesada\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, label in enumerate(labels):\n",
    "    for img, img_label in preprocessed_emojis:\n",
    "        if img_label == label:\n",
    "            plt.subplot(1, 5, i + 1)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(label)\n",
    "            plt.axis('off')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e33451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de los datos para el modelo\n",
    "X = np.array([img for img, label in preprocessed_emojis])\n",
    "y_txt = np.array([labels.index(label)for img, label in preprocessed_emojis])\n",
    "X = X.reshape(-1,36*36).astype('float32')/255.0\n",
    "encoder = LabelEncoder()\n",
    "y_num = encoder.fit_transform(y_txt)\n",
    "y = to_categorical(y_num, num_classes=len(labels))\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeaabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la funcion que crea el modelo MLP con keras\n",
    "def create_mlp(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da02265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena un modelo con los datos de entrenamiento\n",
    "model = create_mlp(input_dim=36*36, num_classes=5)\n",
    "model.summary()\n",
    "model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalua el modelo con los datos de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a9267a",
   "metadata": {},
   "source": [
    "Entrenamiento utilizando una CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc71f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparación de Datos para la CNN\n",
    "\n",
    "X_train_cnn = X_train.reshape(-1, 36, 36, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 36, 36, 1)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Forma de X_train para CNN:\", X_train_cnn.shape)\n",
    "print(\"Forma de X_test para CNN:\", X_test_cnn.shape)\n",
    "print(\"Forma de y_train para CNN:\", y_train.shape) \n",
    "print(\"Forma de y_test para CNN:\", y_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e998545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera la función que crea el modelo CNN\n",
    "def create_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e668921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila y entrena la CNN con los datos de entrenamiento\n",
    "cnn_model = create_cnn(input_shape=(36, 36, 1), num_classes=5)\n",
    "cnn_model.summary() \n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, validation_split=0.2, validation_data=(X_test_cnn, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefa4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa la CNN con los datos de prueba\n",
    "y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "y_pred_classes_cnn = np.argmax(y_pred_cnn, axis=1)\n",
    "print(classification_report(y_true_classes, y_pred_classes_cnn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
